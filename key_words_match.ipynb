{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a3ca65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/manil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/manil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/manil/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2bf65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean_corpus_eng_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d59232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rapper</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>RNP</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Uh, okay, put your fucking hands up, this the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>Kung Fu</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>I'ma just get it and get it again\\nCome ups I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>Bad Idea</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>I know myself all too well to be a stranger of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>Have Mercy</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>There's no complainin' on this side\\nMy niggas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>Old Niggas</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Uh, old niggas and new niggas, now what's the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rapper        song    year  \\\n",
       "0  Cordae         RNP  2019.0   \n",
       "1  Cordae     Kung Fu  2018.0   \n",
       "2  Cordae    Bad Idea  2019.0   \n",
       "3  Cordae  Have Mercy  2019.0   \n",
       "4  Cordae  Old Niggas  2018.0   \n",
       "\n",
       "                                              lyrics  \n",
       "0  Uh, okay, put your fucking hands up, this the ...  \n",
       "1  I'ma just get it and get it again\\nCome ups I ...  \n",
       "2  I know myself all too well to be a stranger of...  \n",
       "3  There's no complainin' on this side\\nMy niggas...  \n",
       "4  Uh, old niggas and new niggas, now what's the ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "230bfab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lyrics\"] = df[\"lyrics\"].apply(lambda text: str(text).replace('|', ' \\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec8b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lyrics_splitted\"] = df[\"lyrics\"].apply(lambda text: str(text).replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b259824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lyrics_splitted_lines\"] = df[\"lyrics\"].apply(lambda text: str(text).splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5f73a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics_tokenized'] = df[\"lyrics_splitted\"].apply(lambda text: ' '.join(word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "810c3e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/manil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f60c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df[\"lyrics_lemmatized\"] = df[\"lyrics_tokenized\"].apply(lambda text: [lemmatizer.lemmatize(word) for word in text.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a69aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"formula_num_sent\"] = df[\"lyrics_splitted_lines\"].apply(lambda text: len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c840d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slurs = pd.read_csv(\"slurs.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f680dbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>canonical_form_1</th>\n",
       "      <th>canonical_form_2</th>\n",
       "      <th>canonical_form_3</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>severity_rating</th>\n",
       "      <th>severity_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@55</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rat baztad</td>\n",
       "      <td>bastard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>animal references</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ape shit</td>\n",
       "      <td>ape</td>\n",
       "      <td>shit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bodily fluids / excrement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ape shite</td>\n",
       "      <td>ape</td>\n",
       "      <td>shit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bodily fluids / excrement</td>\n",
       "      <td>animal references</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text canonical_form_1 canonical_form_2 canonical_form_3  \\\n",
       "0          69               69              NaN              NaN   \n",
       "1         @55              ass              NaN              NaN   \n",
       "2  rat baztad          bastard              NaN              NaN   \n",
       "3    ape shit              ape             shit              NaN   \n",
       "4   ape shite              ape             shit              NaN   \n",
       "\n",
       "                     category_1         category_2 category_3  \\\n",
       "0  sexual anatomy / sexual acts                NaN        NaN   \n",
       "1  sexual anatomy / sexual acts                NaN        NaN   \n",
       "2             animal references                NaN        NaN   \n",
       "3     bodily fluids / excrement                NaN        NaN   \n",
       "4     bodily fluids / excrement  animal references        NaN   \n",
       "\n",
       "   severity_rating severity_description  \n",
       "0              1.0                 Mild  \n",
       "1              1.0                 Mild  \n",
       "2              1.8               Strong  \n",
       "3              1.6               Strong  \n",
       "4              1.6               Strong  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slurs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "600034e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slurs = dict(zip(df_slurs.text, df_slurs.severity_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86a44484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_words(df, slurs: dict) -> list:\n",
    "    df[\"slurs\"] = np.nan\n",
    "    df[\"num_slurs\"] = np.nan\n",
    "    df[\"formula_song\"] = np.nan\n",
    "    for ind, (_, row) in tqdm(enumerate(df.iterrows())):\n",
    "        match_words = []\n",
    "        new_set = set(row[\"lyrics_lemmatized\"])\n",
    "        for word in new_set:\n",
    "            if word in slurs:\n",
    "                match_words.append(word)\n",
    "        row[\"slurs\"] = match_words\n",
    "        row[\"num_slurs\"] = len(row[\"slurs\"])\n",
    "        \n",
    "        formula_song = 0.0\n",
    "        for word in match_words:\n",
    "            formula_song += float(slurs[word])\n",
    "        row[\"formula_song\"] = formula_song / len(row[\"lyrics_tokenized\"])\n",
    "        \n",
    "        df.at[ind] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "add1e045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15280it [01:16, 198.62it/s]\n"
     ]
    }
   ],
   "source": [
    "get_matched_words(df, slurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1733af0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rapper</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lyrics_splitted</th>\n",
       "      <th>lyrics_splitted_lines</th>\n",
       "      <th>lyrics_tokenized</th>\n",
       "      <th>lyrics_lemmatized</th>\n",
       "      <th>formula_num_sent</th>\n",
       "      <th>slurs</th>\n",
       "      <th>num_slurs</th>\n",
       "      <th>formula_song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>RNP</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Uh, okay, put your fucking hands up, this the ...</td>\n",
       "      <td>Uh, okay, put your fucking hands up, this the ...</td>\n",
       "      <td>[Uh, okay, put your fucking hands up, this the...</td>\n",
       "      <td>Uh , okay , put your fucking hands up , this t...</td>\n",
       "      <td>[Uh, ,, okay, ,, put, your, fucking, hand, up,...</td>\n",
       "      <td>29</td>\n",
       "      <td>[fucking, motherfuckin, Fuck, nigga, bitch]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>Kung Fu</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>I'ma just get it and get it again\\nCome ups I ...</td>\n",
       "      <td>I'ma just get it and get it again Come ups I s...</td>\n",
       "      <td>[I'ma just get it and get it again, Come ups I...</td>\n",
       "      <td>I'ma just get it and get it again Come ups I s...</td>\n",
       "      <td>[I'ma, just, get, it, and, get, it, again, Com...</td>\n",
       "      <td>36</td>\n",
       "      <td>[fucking, nigga, bitch, fucked, goddamn]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.005994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>Bad Idea</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>I know myself all too well to be a stranger of...</td>\n",
       "      <td>I know myself all too well to be a stranger of...</td>\n",
       "      <td>[I know myself all too well to be a stranger o...</td>\n",
       "      <td>I know myself all too well to be a stranger of...</td>\n",
       "      <td>[I, know, myself, all, too, well, to, be, a, s...</td>\n",
       "      <td>44</td>\n",
       "      <td>[shit, nigga]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>Have Mercy</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>There's no complainin' on this side\\nMy niggas...</td>\n",
       "      <td>There's no complainin' on this side My niggas,...</td>\n",
       "      <td>[There's no complainin' on this side, My nigga...</td>\n",
       "      <td>There 's no complainin ' on this side My nigga...</td>\n",
       "      <td>[There, 's, no, complainin, ', on, this, side,...</td>\n",
       "      <td>32</td>\n",
       "      <td>[Fuck, shit, nigga, bitch]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.005132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cordae</td>\n",
       "      <td>Old Niggas</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Uh, old niggas and new niggas, now what's the ...</td>\n",
       "      <td>Uh, old niggas and new niggas, now what's the ...</td>\n",
       "      <td>[Uh, old niggas and new niggas, now what's the...</td>\n",
       "      <td>Uh , old niggas and new niggas , now what 's t...</td>\n",
       "      <td>[Uh, ,, old, nigga, and, new, nigga, ,, now, w...</td>\n",
       "      <td>63</td>\n",
       "      <td>[bullshit, fuckin, suck, nigga]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rapper        song    year  \\\n",
       "0  Cordae         RNP  2019.0   \n",
       "1  Cordae     Kung Fu  2018.0   \n",
       "2  Cordae    Bad Idea  2019.0   \n",
       "3  Cordae  Have Mercy  2019.0   \n",
       "4  Cordae  Old Niggas  2018.0   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  Uh, okay, put your fucking hands up, this the ...   \n",
       "1  I'ma just get it and get it again\\nCome ups I ...   \n",
       "2  I know myself all too well to be a stranger of...   \n",
       "3  There's no complainin' on this side\\nMy niggas...   \n",
       "4  Uh, old niggas and new niggas, now what's the ...   \n",
       "\n",
       "                                     lyrics_splitted  \\\n",
       "0  Uh, okay, put your fucking hands up, this the ...   \n",
       "1  I'ma just get it and get it again Come ups I s...   \n",
       "2  I know myself all too well to be a stranger of...   \n",
       "3  There's no complainin' on this side My niggas,...   \n",
       "4  Uh, old niggas and new niggas, now what's the ...   \n",
       "\n",
       "                               lyrics_splitted_lines  \\\n",
       "0  [Uh, okay, put your fucking hands up, this the...   \n",
       "1  [I'ma just get it and get it again, Come ups I...   \n",
       "2  [I know myself all too well to be a stranger o...   \n",
       "3  [There's no complainin' on this side, My nigga...   \n",
       "4  [Uh, old niggas and new niggas, now what's the...   \n",
       "\n",
       "                                    lyrics_tokenized  \\\n",
       "0  Uh , okay , put your fucking hands up , this t...   \n",
       "1  I'ma just get it and get it again Come ups I s...   \n",
       "2  I know myself all too well to be a stranger of...   \n",
       "3  There 's no complainin ' on this side My nigga...   \n",
       "4  Uh , old niggas and new niggas , now what 's t...   \n",
       "\n",
       "                                   lyrics_lemmatized  formula_num_sent  \\\n",
       "0  [Uh, ,, okay, ,, put, your, fucking, hand, up,...                29   \n",
       "1  [I'ma, just, get, it, and, get, it, again, Com...                36   \n",
       "2  [I, know, myself, all, too, well, to, be, a, s...                44   \n",
       "3  [There, 's, no, complainin, ', on, this, side,...                32   \n",
       "4  [Uh, ,, old, nigga, and, new, nigga, ,, now, w...                63   \n",
       "\n",
       "                                         slurs  num_slurs  formula_song  \n",
       "0  [fucking, motherfuckin, Fuck, nigga, bitch]        5.0      0.006993  \n",
       "1     [fucking, nigga, bitch, fucked, goddamn]        5.0      0.005994  \n",
       "2                                [shit, nigga]        2.0      0.001688  \n",
       "3                   [Fuck, shit, nigga, bitch]        4.0      0.005132  \n",
       "4              [bullshit, fuckin, suck, nigga]        4.0      0.002284  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb72a9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Uh, okay, put your fucking hands up, this the fucking anthem\\nSmiling 'cause I'm young, rich, black, and I'm handsome\\nNot to mention wealthy, ass on her healthy\\nYoung millionaire, what the fuck can you tell me? Smell me?\\nNigga, that's Chanel cologne\\nI'm in Europe with the tourists with no cellular phone Like ooh, sound like rich nigga problems\\nI hit a bad bitch with a fistful of condoms\\nAnd the randomness of risky m√©nages\\nLike get the head right, she can get what she wanted\\nThe spits, then flaunt it, my drip like a faucet\\nShe told me she was prego, I ain't even take the motherfuckin' dick out my pocket, yeah The opposite\\nShe want me to fly her, so I copped a jet\\nMust be thinkin' I'm a one way ticket on a runway\\nDrippin' in my feng shui, sippin' on a sundae I bought a Moncler coat for the times we were broke\\nI'ma wear it in the summer on LeBron James boat\\nFront row? Duh, bro, we don't sit on nosebleeds\\nAin't your pockets obese? They won't fit in those seats\\nAyy, we like a cold team, nigga, Shaq and Kobe\\nLike back in '03, I was only like 6\\nShit, I was like 16, but I can give a sixteen\\nI can make a bitch scream, that's a bit extreme\\nI got a thick bald bitch, I call her Ms. Clean\\nMy drip frosty like Halls and Listerine\\nWe all all-stars, you hardly sixth string\\nYeah, I had to ball hard to harvest these dreams\\nSwear to God, me too, no Harvey Weinstein\\nThe coupe was lime green, my wrist was blinding\\nWe party in South Beach, Ferraris and blue cheese\\nFuck does that even mean? Nigga, just let the hook sing\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lyrics\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c00c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"slurs_annotated_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('raply')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "00e949dc05dfbaa6642a176034690ffcdc4b9098c8ac486bc555eb78af2cc4e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
